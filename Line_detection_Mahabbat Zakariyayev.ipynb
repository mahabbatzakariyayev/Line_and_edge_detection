{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbbc1c49",
   "metadata": {},
   "source": [
    "\n",
    "# Line Detection and Edge Detection\n",
    "\n",
    "Prepared by **Mahabbat Zakariyayev** with **enthusiasm**\n",
    "\n",
    "This notebook demonstrates two approaches for detecting linear structures (boundaries) in an image. The first approach uses a set of oriented convolution kernels to highlight edges in specific directions, while the second approach uses the Canny edge detector. Both methods are evaluated against a provided ground‐truth boundary mask using common segmentation metrics such as precision, recall, F1‑score, Intersection over Union (IoU) and balanced accuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d71d730",
   "metadata": {},
   "source": [
    "\n",
    "## Section 1 – Load and Preprocess Image\n",
    "\n",
    "In this section we import the necessary libraries, load the sample image `P0061.png`( I have also applied other images for adding to the presentation), convert it to grayscale and apply Gaussian smoothing. Blurring reduces high‑frequency noise and improves the robustness of subsequent edge detection. A simple visualization of the grayscale image is also provided.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78df0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# I have used cv2 to read the color image\n",
    "img_bgr = cv2.imread(\"P0061.png\")\n",
    "# Converted to grayscale\n",
    "img_gray = cv2.cvtColor(img_bgr, cv2.COLOR_BGR2GRAY)\n",
    "# I have appplied Gaussian blur to reduce noize\n",
    "img_blur = cv2.GaussianBlur(img_gray, (3, 3), 0)\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.title(\"Grayscale Image\")\n",
    "plt.imshow(img_gray, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce3166b2",
   "metadata": {},
   "source": [
    "\n",
    "## Section 2 – Line Detection Using Oriented Kernels\n",
    "\n",
    "To detect line structures in different orientations, we construct four \\(3 \times 3\\) convolution kernels representing horizontal (0°), vertical (90°) and the two diagonal (45° and 135°) directions. We convolve each kernel with the blurred image and take the absolute response. The maximum response across all orientations indicates where a line is present regardless of its direction.\n",
    "\n",
    "An adaptive threshold is created by using the 95th percentile to threshold the maximum response, and the predicted line map is formed of all pixels that have exceeded this threshold. The ground-truth boundary mask is created by using the provided instance mask to contain the object's boundaries, applying dilation and erosion. To quantify performance, we compute a variety of evaluation metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318d4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define oriented 3x3 kernels for line detection\n",
    "k0 = np.array([[-1, -1, -1], [2, 2, 2], [-1, -1, -1]], dtype=np.float32)  # horizontal\n",
    "k90 = np.array([[-1, 2, -1], [-1, 2, -1], [-1, 2, -1]], dtype=np.float32)  # vertical\n",
    "k45 = np.array([[-1, -1, 2], [-1, 2, -1], [2, -1, -1]], dtype=np.float32)  # 45 degrees diagonal\n",
    "k135 = np.array([[2, -1, -1], [-1, 2, -1], [-1, -1, 2]], dtype=np.float32)  # 135 degrees diagonal\n",
    "kernels = [k0, k45, k90, k135]\n",
    "\n",
    "# Convolve each kernel with the blurred image\n",
    "responses = [cv2.filter2D(img_blur, cv2.CV_32F, k) for k in kernels]\n",
    "R0, R45, R90, R135 = responses\n",
    "\n",
    "# Stack responses and take the maximum absolute response across all orientations\n",
    "stacked = np.stack([np.abs(R0), np.abs(R45), np.abs(R90), np.abs(R135)], axis=-1)\n",
    "R_max = np.max(stacked, axis=-1)\n",
    "\n",
    "# Thresholded using the 95 percentile of the response values to obtain a binary line map below\n",
    "T = np.percentile(R_max, 95)\n",
    "line_map = (R_max > T).astype(np.uint8)\n",
    "\n",
    "# Loaded the ground‑truth instance mask and compute a boundary mask after some retries\n",
    "gt_raw = cv2.imread(\"images/P0061_instance_color_RGB.png\", cv2.IMREAD_GRAYSCALE)\n",
    "if gt_raw is None:\n",
    "    raise FileNotFoundError(\"Could not load images/P0061_instance_color_RGB.png. Please ensure the ground‑truth mask is available.\")\n",
    "\n",
    "semantic = (gt_raw > 0).astype(np.uint8) * 255\n",
    "kernel = np.ones((3, 3), np.uint8)\n",
    "dil = cv2.dilate(semantic, kernel, iterations=1)\n",
    "ero = cv2.erode(semantic, kernel, iterations=1)\n",
    "gt = ((dil - ero) > 0).astype(np.uint8)\n",
    "\n",
    "# Evaluate predicted line map against ground truth \n",
    "pred = line_map.astype(np.uint8)\n",
    "\n",
    "TP = np.logical_and(pred == 1, gt == 1).sum()\n",
    "FP = np.logical_and(pred == 1, gt == 0).sum()\n",
    "FN = np.logical_and(pred == 0, gt == 1).sum()\n",
    "TN = np.logical_and(pred == 0, gt == 0).sum()\n",
    "\n",
    "precision = TP / (TP + FP + 1e-9)\n",
    "recall    = TP / (TP + FN + 1e-9)\n",
    "f1_score  = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "iou       = TP / (TP + FP + FN + 1e-9)\n",
    "accuracy  = (TP + TN) / (TP + FP + FN + TN + 1e-9)\n",
    "specificity = TN / (TN + FP + 1e-9)\n",
    "dice = f1_score\n",
    "fpr = FP / (FP + TN + 1e-9)\n",
    "fnr = FN / (TP + FN + 1e-9)\n",
    "balanced_accuracy = (recall + specificity) / 2\n",
    "\n",
    "#Some(too many) print statements to show the metrics :)\n",
    "print(f\"TP, FP, FN, TN: {TP}, {FP}, {FN}, {TN}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score (Dice): {f1_score:.4f}\")\n",
    "print(f\"IoU: {iou:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"FPR: {fpr:.4f}\")\n",
    "print(f\"FNR: {fnr:.4f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy:.4f}\")\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Maximum Line Response\")\n",
    "plt.imshow(R_max, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Predicted Line Map\")\n",
    "plt.imshow(pred, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Ground Truth Boundary Mask\")\n",
    "plt.imshow(gt, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71acd26",
   "metadata": {},
   "source": [
    "\n",
    "## Section 3 – Canny Edge Detection\n",
    "\n",
    "The Canny operator is a classic multi‑stage edge detector. We first apply the same Gaussian blur used earlier to suppress noise. Then we call `cv2.Canny` with low and high thresholds to obtain a binary edge map. As before, we compare the predicted edges with the boundary mask and compute identical evaluation metrics. Varying the thresholds will adjust the sensitivity of the detector.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1f69d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#I have defined low and high hysteresis thresholds for Canny\n",
    "t_low = 50\n",
    "t_high = 150\n",
    "\n",
    "# I have Computed Canny edges on the blurred grayscale image\n",
    "edges = cv2.Canny(img_blur, t_low, t_high)\n",
    "\n",
    "# Converted the edge map to binary prediction mask\n",
    "pred_canny = (edges > 0).astype(np.uint8)\n",
    "\n",
    "# Evaluated the  predicted edges against the same ground truth boundary mask here \n",
    "TP = np.logical_and(pred_canny == 1, gt == 1).sum()\n",
    "FP = np.logical_and(pred_canny == 1, gt == 0).sum()\n",
    "FN = np.logical_and(pred_canny == 0, gt == 1).sum()\n",
    "TN = np.logical_and(pred_canny == 0, gt == 0).sum()\n",
    "\n",
    "precision = TP / (TP + FP + 1e-9)\n",
    "recall    = TP / (TP + FN + 1e-9)\n",
    "f1_score  = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "iou       = TP / (TP + FP + FN + 1e-9)\n",
    "accuracy  = (TP + TN) / (TP + FP + FN + TN + 1e-9)\n",
    "specificity = TN / (TN + FP + 1e-9)\n",
    "fpr = FP / (FP + TN + 1e-9)\n",
    "fnr = FN / (TP + FN + 1e-9)\n",
    "balanced_accuracy = (recall + specificity) / 2\n",
    "\n",
    "print(f\"TP, FP, FN, TN: {TP}, {FP}, {FN}, {TN}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score (Dice): {f1_score:.4f}\")\n",
    "print(f\"IoU: {iou:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(f\"FPR: {fpr:.4f}\")\n",
    "print(f\"FNR: {fnr:.4f}\")\n",
    "print(f\"Balanced Accuracy: {balanced_accuracy:.4f}\")\n",
    "\n",
    "# Visualizeed my resultws\n",
    "plt.figure(figsize=(12, 12))\n",
    "\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.title(\"Blurred Image\")\n",
    "plt.imshow(img_blur, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.title(\"Canny Edge Map\")\n",
    "plt.imshow(pred_canny, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.title(\"Ground Truth Boundary Mask\") x\n",
    "plt.imshow(gt, cmap=\"gray\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12175c2d",
   "metadata": {},
   "source": [
    "\n",
    "## Conclusion\n",
    "In this notebook, the Canny edge detector and a simple Oriented Kernel method were directly compared for detecting boundaries within a test image. While the Oriented Kernel method isolated edges based on their orientations and combined them together to build a skeleton of detected edges, the Canny edge detection process utilized gradient magnitude on the image and applied non-maximum suppression on these values, followed by thresholding to provide binary edge images. The results from both methods produced edge maps with accurate edge locations when using threshold values and kernel orientations that are properly set. As metrics such as Precision, Recall, F1-score, IoU, etc., are used to evaluate the Canny edge detector's performance, these metrics can be quantitatively compared with the true boundary masks to evaluate the quality of the Canny edge detector's edges.\n",
    "\n",
    "Thank you for reading!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.12.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
